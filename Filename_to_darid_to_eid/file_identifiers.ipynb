{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_names_raw = open('dar_all_jpg_filenames.txt').read().split('\\n')\n",
    "image_names = set()\n",
    "\n",
    "for name in image_names_raw:\n",
    "    name = name.lower()\n",
    "    if name.endswith('.jpg'):\n",
    "        image_names.add(name.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relates the image \"filename\" to the \"eid\" (useful for finding the images at their URLS), \"class_mark\" (useful for relating the images to the text transcript) and to \"sort_class_mark\" (which might be useful!). NOTE: Strip your filenames before searching! Some filenames have leading spaces (yes, actually) as the spaces are not included here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify useful csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_good_csvs(PATH):\n",
    "    \n",
    "    csvs = []\n",
    "\n",
    "    for directory in os.walk(PATH):\n",
    "        dirpath, _, files = directory\n",
    "        for f in files:\n",
    "            try:\n",
    "                f = f.strip()\n",
    "                if f.endswith('.csv') and 'MS-DAR-' in f and not f.startswith('.'):\n",
    "                    \n",
    "                    file_path = os.path.join(dirpath, f)\n",
    "                    \n",
    "                    with open(file_path, encoding='latin8') as f_file:\n",
    "                        header = f_file.readline()\n",
    "                        if len(header) > 500:\n",
    "                            print(f + \" is not ideal\")\n",
    "\n",
    "                        if 'filename' in header.lower():\n",
    "                            csvs.append(file_path)\n",
    "\n",
    "            except:\n",
    "                traceback.format_exc()\n",
    "                break\n",
    "\n",
    "    return csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate_good_csvs(good_csvs):\n",
    "    \n",
    "    dfs = []\n",
    "    for csv in good_csvs:\n",
    "        dfs.append(pd.read_csv(csv, encoding='latin8'))\n",
    "\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_csvs = find_good_csvs('/home/jacob/Downloads/hackathon/data/Original_transcript_folder_from_AMNH/')\n",
    "data = concatenate_good_csvs(good_csvs)\n",
    "\n",
    "data = data[['eid', 'filename', 'class-mark', 'sort-class-mark']]\n",
    "\n",
    "data.drop_duplicates(inplace=True)\n",
    "data = data[data.filename.notnull()]\n",
    "data['eid'] = data['eid'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_file_names(file_name, group):\n",
    "    \n",
    "    if len(group) == 1:\n",
    "        return group.as_matrix()[0]\n",
    "    \n",
    "    eid = set(group.eid.dropna().values)\n",
    "    class_mark = set(group['class-mark'].dropna().values)\n",
    "    sort_class_mark = set(group['sort-class-mark'].dropna().values)\n",
    "\n",
    "    if len(eid) > 1 or len(class_mark) > 1 or len(sort_class_mark) > 1:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    return np.array([file_name, eid.pop(), class_mark.pop(), sort_class_mark.pop()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_final_files_names():\n",
    "\n",
    "    final_file_names = []\n",
    "\n",
    "    for file_name, group in data.groupby('filename'):\n",
    "\n",
    "        row = filter_file_names(file_name, group)\n",
    "\n",
    "        if row is not None:\n",
    "            final_file_names.append(row)\n",
    "\n",
    "    return np.array(final_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_file_names = get_final_files_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_file_names = pd.DataFrame.from_records(final_file_names, columns=['file_name', 'eid', 'class_mark', 'sort_class_mark'])\n",
    "final_file_names.to_csv('file_identifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's find some reverse things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('file_identifiers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47537243691935571"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_class_mark.str.lower().str.endswith('v').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48133692485294927"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_class_mark.str.lower().str.endswith('r').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_orientation(sort_class_mark):\n",
    "    \n",
    "    sort_class_mark = sort_class_mark.lower().strip()\n",
    "    \n",
    "    if sort_class_mark.endswith('v'):\n",
    "        return 'v'\n",
    "    \n",
    "    if sort_class_mark.endswith('r'):\n",
    "        return 'r'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['orientation'] = data.sort_class_mark.apply(find_orientation)\n",
    "data.to_csv('file_identifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29633"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data.filename.str.lower().values).intersection(image_names))#/len(image_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
